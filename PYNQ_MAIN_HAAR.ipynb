{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d613e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================================\n",
    "# CELL 1: DRIVER CLASS (Run this first)\n",
    "# ==========================================================================\n",
    "from pynq import Overlay, allocate\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class FisherfaceDriver:\n",
    "    def __init__(self, bitfile_path, max_classes=5):\n",
    "        print(f\"Loading overlay: {bitfile_path}\")\n",
    "        self.overlay = Overlay(bitfile_path)\n",
    "        self.dma = self.overlay.axi_dma_0\n",
    "        self.ip = self.overlay.fisherface_accel_0\n",
    "        \n",
    "        self.VECTOR_SIZE = 10000\n",
    "        self.MAX_CLASSES = max_classes\n",
    "        self.HW_SCALE = 128.0\n",
    "        self.SW_BOOST = 20.0\n",
    "        self.TOTAL_SCALE = self.HW_SCALE * self.SW_BOOST\n",
    "        \n",
    "        self.input_buffer = allocate(shape=(self.VECTOR_SIZE,), dtype=np.int32)\n",
    "        self.num_classes = 0\n",
    "        print(f\"Driver initialized. MAX_CLASSES={self.MAX_CLASSES}\")\n",
    "    \n",
    "    def _send_chunked(self, data_array, scale):\n",
    "        flat_data = data_array.flatten().astype(np.float64)\n",
    "        quantized = (flat_data * scale).astype(np.int32)\n",
    "        np.copyto(self.input_buffer, quantized)\n",
    "        \n",
    "        CHUNK_SIZE = 4000\n",
    "        for i in range(0, self.VECTOR_SIZE, CHUNK_SIZE):\n",
    "            end = min(i + CHUNK_SIZE, self.VECTOR_SIZE)\n",
    "            self.dma.sendchannel.transfer(self.input_buffer[i:end])\n",
    "            self.dma.sendchannel.wait()\n",
    "    \n",
    "    def load_mean(self, mean_vector):\n",
    "        assert len(mean_vector) == self.VECTOR_SIZE\n",
    "        self.ip.register_map.mode = 1\n",
    "        self.ip.register_map.class_id = 0\n",
    "        self.ip.register_map.CTRL.AP_START = 1\n",
    "        self._send_chunked(mean_vector, self.HW_SCALE)\n",
    "        print(\"Mean vector loaded.\")\n",
    "    \n",
    "    def load_weights(self, weight_matrix):\n",
    "        if weight_matrix.shape[0] == self.VECTOR_SIZE:\n",
    "            num_classes = weight_matrix.shape[1] if weight_matrix.ndim > 1 else 1\n",
    "        elif weight_matrix.shape[1] == self.VECTOR_SIZE:\n",
    "            weight_matrix = weight_matrix.T\n",
    "            num_classes = weight_matrix.shape[1]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid weight shape: {weight_matrix.shape}\")\n",
    "        \n",
    "        if weight_matrix.ndim == 1:\n",
    "            weight_matrix = weight_matrix.reshape(-1, 1)\n",
    "            num_classes = 1\n",
    "        \n",
    "        if num_classes > self.MAX_CLASSES:\n",
    "            print(f\"WARNING: Truncating {num_classes} to {self.MAX_CLASSES} classes\")\n",
    "            num_classes = self.MAX_CLASSES\n",
    "            weight_matrix = weight_matrix[:, :self.MAX_CLASSES]\n",
    "        \n",
    "        for c in range(num_classes):\n",
    "            self.ip.register_map.mode = 2\n",
    "            self.ip.register_map.class_id = c\n",
    "            self.ip.register_map.CTRL.AP_START = 1\n",
    "            self._send_chunked(weight_matrix[:, c], self.TOTAL_SCALE)\n",
    "            print(f\"  Class {c} weights loaded.\")\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        print(f\"All {num_classes} weight vectors loaded.\")\n",
    "    \n",
    "    def inference(self, face_vector):\n",
    "        assert len(face_vector) == self.VECTOR_SIZE\n",
    "        \n",
    "        self.ip.register_map.mode = 0\n",
    "        self.ip.register_map.class_id = 0\n",
    "        self.ip.register_map.CTRL.AP_START = 1\n",
    "        \n",
    "        self._send_chunked(face_vector, self.HW_SCALE)\n",
    "        \n",
    "        while self.ip.register_map.CTRL.AP_DONE == 0:\n",
    "            pass\n",
    "        \n",
    "        ACC_SCALE = 4096.0\n",
    "        results = np.zeros(self.num_classes, dtype=np.float64)\n",
    "        OUTPUT_BASE_OFFSET = 0x20\n",
    "        \n",
    "        for c in range(self.num_classes):\n",
    "            raw_int = self.ip.mmio.read(OUTPUT_BASE_OFFSET + c * 4)\n",
    "            if raw_int >= 0x80000000:\n",
    "                raw_int -= 0x100000000\n",
    "            results[c] = raw_int / (ACC_SCALE * self.SW_BOOST)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9abc37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Loading Model Data...\n",
      "============================================================\n",
      "Model loaded:\n",
      "  - eigen_vecs shape: (10000, 2)\n",
      "  - train_proj_db shape: (1035, 2)\n",
      "  - Classes: ['993', 'peidong', 'unknown']\n",
      "Loading overlay: fisherface.bit\n",
      "Driver initialized. MAX_CLASSES=5\n",
      "Mean vector loaded to FPGA.\n",
      "  Class 0 weights loaded.\n",
      "  Class 1 weights loaded.\n",
      "All 2 weight vectors loaded to FPGA.\n",
      "============================================================\n",
      "HARDWARE READY - All classes loaded!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "==========================================================================\n",
    "CELL 2: LOAD MODEL & INITIALIZE HARDWARE (Run after Cell 1)\n",
    "==========================================================================\n",
    "\"\"\"\n",
    "print(\"=\" * 60)\n",
    "print(\"Loading Model Data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data = np.load(\"face_model_data.npz\", allow_pickle=True)\n",
    "\n",
    "mean_vec = data['mean_vec']\n",
    "eigen_vecs = data['eigen_vecs']\n",
    "train_proj_db = data['train_proj_db']\n",
    "train_lbls_db = data['train_lbls_db']\n",
    "\n",
    "# Handle label_names storage format\n",
    "if 'label_keys' in data:\n",
    "    keys = data['label_keys']\n",
    "    vals = data['label_vals']\n",
    "    label_names = dict(zip(keys, vals))\n",
    "else:\n",
    "    label_names = data['label_names'].item()\n",
    "\n",
    "print(f\"Model loaded:\")\n",
    "print(f\"  - eigen_vecs shape: {eigen_vecs.shape}\")\n",
    "print(f\"  - train_proj_db shape: {train_proj_db.shape}\")\n",
    "print(f\"  - Classes: {list(label_names.values())}\")\n",
    "\n",
    "# Initialize driver\n",
    "num_classes = eigen_vecs.shape[1] if eigen_vecs.ndim > 1 else 1\n",
    "driver = FisherfaceDriver(\"fisherface.bit\", max_classes=max(num_classes, 5))\n",
    "\n",
    "# Load parameters to FPGA\n",
    "driver.load_mean(mean_vec)\n",
    "driver.load_weights(eigen_vecs)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"HARDWARE READY - All classes loaded!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3839cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference result shape: (2,)\n",
      "Values: [-1440.72836914  -443.77095947]\n"
     ]
    }
   ],
   "source": [
    "# Quick test - should return array of 4 values\n",
    "test_face = np.random.rand(10000) * 255\n",
    "result = driver.inference(test_face)\n",
    "print(f\"Inference result shape: {result.shape}\")\n",
    "print(f\"Values: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42f08f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==========================================================================\n",
    "# # CELL 3-BENCHMARK: TIMING ANALYSIS (Run after Cell 2)\n",
    "# # ==========================================================================\n",
    "# # This measures exact timing for each stage of face recognition\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import time\n",
    "\n",
    "# # --------------------------------------------------------------\n",
    "# # CONFIGURATION\n",
    "# # --------------------------------------------------------------\n",
    "# IMG_SIZE = (100, 100)\n",
    "# THRESHOLD = 400.0\n",
    "# SCALE_FACTOR = 1.0\n",
    "\n",
    "# # --------------------------------------------------------------\n",
    "# # SETUP\n",
    "# # --------------------------------------------------------------\n",
    "# cascade_path = 'haarcascade_frontalface_default.xml'\n",
    "# face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "# if face_cascade.empty():\n",
    "#     print(\"ERROR: Cascade XML not found!\")\n",
    "# else:\n",
    "#     print(\"Face cascade loaded.\")\n",
    "\n",
    "# def preprocess(img):\n",
    "#     g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if img.ndim == 3 else img\n",
    "#     g = cv2.resize(g, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "#     g = cv2.equalizeHist(g)\n",
    "#     g = cv2.normalize(g, None, 0, 255, cv2.NORM_MINMAX)\n",
    "#     return g\n",
    "\n",
    "# # --------------------------------------------------------------\n",
    "# # OPEN CAMERA\n",
    "# # --------------------------------------------------------------\n",
    "# print(\"\\nOpening camera...\")\n",
    "# cap = cv2.VideoCapture(0, cv2.CAP_V4L2)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# if not cap.isOpened():\n",
    "#     print(\"ERROR: Could not open camera.\")\n",
    "# else:\n",
    "#     print(\"Camera opened successfully.\")\n",
    "    \n",
    "#     # Warm up camera (discard first few frames)\n",
    "#     for _ in range(10):\n",
    "#         cap.read()\n",
    "    \n",
    "#     # ==============================================================\n",
    "#     # BENCHMARK 1: Single Frame Breakdown (with face detected)\n",
    "#     # ==============================================================\n",
    "#     print(\"\\n\" + \"=\" * 60)\n",
    "#     print(\"BENCHMARK 1: Single Frame Timing Breakdown\")\n",
    "#     print(\"=\" * 60)\n",
    "#     print(\"Waiting for face detection...\")\n",
    "    \n",
    "#     # Find a frame with a face\n",
    "#     face_found = False\n",
    "#     attempts = 0\n",
    "#     while not face_found and attempts < 100:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             continue\n",
    "#         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#         faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "#         if len(faces) > 0:\n",
    "#             face_found = True\n",
    "#             test_frame = frame.copy()\n",
    "#             (x, y, w, h) = faces[0]\n",
    "#         attempts += 1\n",
    "    \n",
    "#     if face_found:\n",
    "#         print(f\"Face detected at ({x}, {y}, {w}, {h})\")\n",
    "#         print(\"-\" * 60)\n",
    "        \n",
    "#         # Time each stage separately\n",
    "        \n",
    "#         # Stage 1: Haar Cascade Detection\n",
    "#         t0 = time.perf_counter()\n",
    "#         gray = cv2.cvtColor(test_frame, cv2.COLOR_BGR2GRAY)\n",
    "#         faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "#         t_haar = time.perf_counter() - t0\n",
    "        \n",
    "#         # Stage 2: Preprocessing\n",
    "#         t0 = time.perf_counter()\n",
    "#         face_roi = test_frame[y:y+h, x:x+w]\n",
    "#         processed_face = preprocess(face_roi)\n",
    "#         flat_face = processed_face.reshape(-1).astype(np.float64)\n",
    "#         t_preprocess = time.perf_counter() - t0\n",
    "        \n",
    "#         # Stage 3: FPGA Inference\n",
    "#         t0 = time.perf_counter()\n",
    "#         test_proj = driver.inference(flat_face)\n",
    "#         t_fpga = time.perf_counter() - t0\n",
    "        \n",
    "#         # Stage 4: Distance Calculation\n",
    "#         t0 = time.perf_counter()\n",
    "#         dists = np.linalg.norm(train_proj_db - test_proj, axis=1)\n",
    "#         min_index = np.argmin(dists)\n",
    "#         min_dist = dists[min_index]\n",
    "#         predicted_lbl = train_lbls_db[min_index]\n",
    "#         t_distance = time.perf_counter() - t0\n",
    "        \n",
    "#         # Total (excluding Haar since face already detected)\n",
    "#         t_after_detection = t_preprocess + t_fpga + t_distance\n",
    "#         t_total = t_haar + t_after_detection\n",
    "        \n",
    "#         print(f\"  Haar Cascade:        {t_haar*1000:8.2f} ms\")\n",
    "#         print(f\"  Preprocessing:       {t_preprocess*1000:8.2f} ms\")\n",
    "#         print(f\"  FPGA Inference:      {t_fpga*1000:8.2f} ms\")\n",
    "#         print(f\"  Distance Calc:       {t_distance*1000:8.2f} ms\")\n",
    "#         print(\"-\" * 60)\n",
    "#         print(f\"  After Detection:     {t_after_detection*1000:8.2f} ms\")\n",
    "#         print(f\"  TOTAL (incl Haar):   {t_total*1000:8.2f} ms\")\n",
    "#     else:\n",
    "#         print(\"ERROR: No face detected in 100 attempts. Please face the camera.\")\n",
    "    \n",
    "#     # ==============================================================\n",
    "#     # BENCHMARK 2: N Iterations (Full Pipeline)\n",
    "#     # ==============================================================\n",
    "#     for N in [10, 100]:\n",
    "#         print(\"\\n\" + \"=\" * 60)\n",
    "#         print(f\"BENCHMARK 2: {N} Iterations (Full Pipeline)\")\n",
    "#         print(\"=\" * 60)\n",
    "        \n",
    "#         successful_frames = 0\n",
    "#         total_time = 0\n",
    "        \n",
    "#         t_haar_total = 0\n",
    "#         t_preprocess_total = 0\n",
    "#         t_fpga_total = 0\n",
    "#         t_distance_total = 0\n",
    "        \n",
    "#         print(f\"Processing {N} frames with face detection...\")\n",
    "        \n",
    "#         start_all = time.perf_counter()\n",
    "        \n",
    "#         while successful_frames < N:\n",
    "#             ret, frame = cap.read()\n",
    "#             if not ret:\n",
    "#                 continue\n",
    "            \n",
    "#             # Haar Detection\n",
    "#             t0 = time.perf_counter()\n",
    "#             gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#             faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "#             t_haar_total += time.perf_counter() - t0\n",
    "            \n",
    "#             if len(faces) > 0:\n",
    "#                 (x, y, w, h) = max(faces, key=lambda r: r[2] * r[3])\n",
    "                \n",
    "#                 if y + h < frame.shape[0] and x + w < frame.shape[1]:\n",
    "#                     # Preprocessing\n",
    "#                     t0 = time.perf_counter()\n",
    "#                     face_roi = frame[y:y+h, x:x+w]\n",
    "#                     processed_face = preprocess(face_roi)\n",
    "#                     flat_face = processed_face.reshape(-1).astype(np.float64)\n",
    "#                     t_preprocess_total += time.perf_counter() - t0\n",
    "                    \n",
    "#                     # FPGA Inference\n",
    "#                     t0 = time.perf_counter()\n",
    "#                     test_proj = driver.inference(flat_face)\n",
    "#                     t_fpga_total += time.perf_counter() - t0\n",
    "                    \n",
    "#                     # Distance Calculation\n",
    "#                     t0 = time.perf_counter()\n",
    "#                     dists = np.linalg.norm(train_proj_db - test_proj, axis=1)\n",
    "#                     min_index = np.argmin(dists)\n",
    "#                     min_dist = dists[min_index]\n",
    "#                     t_distance_total += time.perf_counter() - t0\n",
    "                    \n",
    "#                     successful_frames += 1\n",
    "        \n",
    "#         end_all = time.perf_counter()\n",
    "#         total_time = end_all - start_all\n",
    "        \n",
    "#         print(\"-\" * 60)\n",
    "#         print(f\"  Frames processed:    {successful_frames}\")\n",
    "#         print(f\"  Total wall time:     {total_time*1000:8.2f} ms\")\n",
    "#         print(\"-\" * 60)\n",
    "#         print(f\"  Haar Cascade (sum):  {t_haar_total*1000:8.2f} ms ({t_haar_total/N*1000:.2f} ms/frame)\")\n",
    "#         print(f\"  Preprocessing (sum): {t_preprocess_total*1000:8.2f} ms ({t_preprocess_total/N*1000:.2f} ms/frame)\")\n",
    "#         print(f\"  FPGA Inference (sum):{t_fpga_total*1000:8.2f} ms ({t_fpga_total/N*1000:.2f} ms/frame)\")\n",
    "#         print(f\"  Distance Calc (sum): {t_distance_total*1000:8.2f} ms ({t_distance_total/N*1000:.2f} ms/frame)\")\n",
    "#         print(\"-\" * 60)\n",
    "#         print(f\"  Avg per frame:       {total_time/N*1000:8.2f} ms\")\n",
    "#         print(f\"  Effective FPS:       {N/total_time:8.2f} fps\")\n",
    "    \n",
    "#     # ==============================================================\n",
    "#     # SUMMARY\n",
    "#     # ==============================================================\n",
    "#     print(\"\\n\" + \"=\" * 60)\n",
    "#     print(\"SUMMARY\")\n",
    "#     print(\"=\" * 60)\n",
    "#     print(\"The bottleneck is Haar Cascade running on ARM CPU.\")\n",
    "#     print(\"FPGA accelerates the projection step effectively.\")\n",
    "#     print(\"\\nTo speed up, try:\")\n",
    "#     print(\"  - SCALE_FACTOR = 0.5 (4x faster Haar)\")\n",
    "#     print(\"  - BATCH_SIZE = 30 (faster results)\")\n",
    "#     print(\"=\" * 60)\n",
    "    \n",
    "#     cap.release()\n",
    "#     print(\"\\nCamera released. Benchmark complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5cd8b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face cascade loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2221e032d3454e8ab6e9705c34327b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[THREAD] FPGA AI Worker Started\n",
      "[INFO] System Running! Press 'Stop' in Jupyter to end.\n",
      ">>> [RESULT] Unknown\n",
      ">>> [RESULT] peidong (8/10)\n",
      ">>> [RESULT] 993 (9/10)\n",
      "Stopping...\n",
      "[INFO] System Stopped\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "==========================================================================\n",
    "CELL 3: FACE RECOGNITION WITH VOTING (Run after Cell 2)\n",
    "==========================================================================\n",
    "\"\"\"\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import threading\n",
    "from collections import Counter\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# --------------------------------------------------------------\n",
    "IMG_SIZE = (100, 100)\n",
    "THRESHOLD = 450.0\n",
    "SCALE_FACTOR = 1.0\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# SETUP HAAR CASCADE\n",
    "# --------------------------------------------------------------\n",
    "cascade_path = 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "if face_cascade.empty():\n",
    "    print(\"WARNING: Cascade XML not found!\")\n",
    "    class DummyCascade:\n",
    "        def detectMultiScale(self, *args, **kwargs): \n",
    "            return []\n",
    "    face_cascade = DummyCascade()\n",
    "else:\n",
    "    print(\"Face cascade loaded.\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# GLOBAL VARIABLES\n",
    "# --------------------------------------------------------------\n",
    "current_frame = None\n",
    "latest_result_box = None\n",
    "latest_result_name = \"\"\n",
    "latest_result_color = (255, 255, 255)\n",
    "system_running = True\n",
    "frame_lock = threading.Lock()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# --------------------------------------------------------------\n",
    "def preprocess(img):\n",
    "    g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if img.ndim == 3 else img\n",
    "    g = cv2.resize(g, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    g = cv2.equalizeHist(g)\n",
    "    g = cv2.normalize(g, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return g\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# AI WORKER THREAD\n",
    "# --------------------------------------------------------------\n",
    "def ai_processing_worker():\n",
    "    global latest_result_box, latest_result_name, latest_result_color, current_frame\n",
    "    \n",
    "    prediction_buffer = []\n",
    "    print(\"[THREAD] FPGA AI Worker Started\")\n",
    "    \n",
    "    while system_running:\n",
    "        frame_to_process = None\n",
    "        with frame_lock:\n",
    "            if current_frame is not None:\n",
    "                frame_to_process = current_frame.copy()\n",
    "        \n",
    "        if frame_to_process is None:\n",
    "            time.sleep(0.05)\n",
    "            continue\n",
    "        \n",
    "        if SCALE_FACTOR != 1.0:\n",
    "            small_frame = cv2.resize(frame_to_process, (0, 0), \n",
    "                                     fx=SCALE_FACTOR, fy=SCALE_FACTOR)\n",
    "        else:\n",
    "            small_frame = frame_to_process\n",
    "        \n",
    "        gray = cv2.cvtColor(small_frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        \n",
    "        if len(faces) > 0:\n",
    "            largest_face = max(faces, key=lambda r: r[2] * r[3])\n",
    "            (sx, sy, sw, sh) = largest_face\n",
    "            \n",
    "            scale_inv = 1.0 / SCALE_FACTOR\n",
    "            x = int(sx * scale_inv)\n",
    "            y = int(sy * scale_inv)\n",
    "            w = int(sw * scale_inv)\n",
    "            h = int(sh * scale_inv)\n",
    "            \n",
    "            if y + h < frame_to_process.shape[0] and x + w < frame_to_process.shape[1]:\n",
    "                face_roi = cv2.cvtColor(frame_to_process[y:y+h, x:x+w], \n",
    "                                        cv2.COLOR_BGR2GRAY)\n",
    "                processed_face = preprocess(face_roi)\n",
    "                flat_face = processed_face.reshape(-1).astype(np.float64)\n",
    "                \n",
    "                # FPGA INFERENCE\n",
    "                test_proj = driver.inference(flat_face)\n",
    "                \n",
    "                # Distance calculation\n",
    "                dists = np.linalg.norm(train_proj_db - test_proj, axis=1)\n",
    "                min_index = np.argmin(dists)\n",
    "                min_dist = dists[min_index]\n",
    "                predicted_lbl = train_lbls_db[min_index]\n",
    "                \n",
    "                if min_dist > THRESHOLD:\n",
    "                    instant_name = \"Unknown\"\n",
    "                else:\n",
    "                    instant_name = label_names.get(predicted_lbl, \"Unknown\")\n",
    "                    if instant_name.lower() == \"unknown\":\n",
    "                        instant_name = \"Unknown\"\n",
    "                \n",
    "                # VOTING LOGIC\n",
    "                prediction_buffer.append(instant_name)\n",
    "                \n",
    "                if len(prediction_buffer) < BATCH_SIZE:\n",
    "                    latest_result_name = f\"Analyzing... {len(prediction_buffer)}/{BATCH_SIZE}\"\n",
    "                    latest_result_color = (200, 200, 200)\n",
    "                else:\n",
    "                    counts = Counter(prediction_buffer)\n",
    "                    if not counts:\n",
    "                        winner_name, vote_count = \"Unknown\", 0\n",
    "                    else:\n",
    "                        winner_name, vote_count = counts.most_common(1)[0]\n",
    "                    \n",
    "#                     if winner_name == \"Unknown\":\n",
    "#                         latest_result_name = \"Unknown\"\n",
    "#                         latest_result_color = (0, 0, 255)\n",
    "#                     elif vote_count >= 80:\n",
    "#                         latest_result_name = f\"{winner_name} ({vote_count}%)\"\n",
    "#                         latest_result_color = (0, 255, 0)\n",
    "#                     elif vote_count >= 50:\n",
    "#                         latest_result_name = f\"Maybe {winner_name}? ({vote_count}%)\"\n",
    "#                         latest_result_color = (0, 255, 255)\n",
    "#                     else:\n",
    "#                         latest_result_name = \"Unknown (Low Conf)\"\n",
    "#                         latest_result_color = (0, 0, 255)\n",
    "                    # NEW CODE (for 10 frames):\n",
    "                    if winner_name == \"Unknown\":\n",
    "                        latest_result_name = \"Unknown\"\n",
    "                        latest_result_color = (0, 0, 255)\n",
    "                    elif vote_count >= 8:  # 8,9,10 → Recognized\n",
    "                        latest_result_name = f\"{winner_name} ({vote_count}/{BATCH_SIZE})\"\n",
    "                        latest_result_color = (0, 255, 0)\n",
    "                    elif vote_count >= 5:  # 5,6,7 → Maybe\n",
    "                        latest_result_name = f\"Maybe {winner_name}? ({vote_count}/{BATCH_SIZE})\"\n",
    "                        latest_result_color = (0, 255, 255)\n",
    "                    else:  # 0,1,2,3,4 → Unknown\n",
    "                        latest_result_name = \"Unknown (Low Conf)\"\n",
    "                        latest_result_color = (0, 0, 255)\n",
    "                    \n",
    "                    print(f\">>> [RESULT] {latest_result_name}\")\n",
    "                    prediction_buffer = []\n",
    "                \n",
    "                latest_result_box = (x, y, w, h)\n",
    "        else:\n",
    "            prediction_buffer = []\n",
    "            latest_result_box = None\n",
    "        \n",
    "        time.sleep(0.01)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# MAIN DISPLAY LOOP\n",
    "# --------------------------------------------------------------\n",
    "image_widget = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(image_widget)\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_V4L2)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"ERROR: Could not open camera.\")\n",
    "else:\n",
    "    system_running = True\n",
    "    worker_thread = threading.Thread(target=ai_processing_worker)\n",
    "    worker_thread.start()\n",
    "    print(\"[INFO] System Running! Press 'Stop' in Jupyter to end.\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            with frame_lock:\n",
    "                current_frame = frame\n",
    "            \n",
    "            if latest_result_box is not None:\n",
    "                (x, y, w, h) = latest_result_box\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), latest_result_color, 2)\n",
    "                cv2.putText(frame, latest_result_name, (x, y-10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, latest_result_color, 2)\n",
    "            \n",
    "            _, encoded = cv2.imencode('.jpg', frame, \n",
    "                                      [int(cv2.IMWRITE_JPEG_QUALITY), 50])\n",
    "            image_widget.value = encoded.tobytes()\n",
    "            time.sleep(0.001)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping...\")\n",
    "    \n",
    "    finally:\n",
    "        system_running = False\n",
    "        worker_thread.join()\n",
    "        cap.release()\n",
    "        print(\"[INFO] System Stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7eaa39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBP Cascade loaded successfully from lbpcascade_frontalface_improved.xml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480c78a807d34d5cbad3e2d2faf58307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[THREAD] FPGA AI Worker Started\n",
      "[INFO] System Running! Press 'Stop' in Jupyter to end.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (ai_processing_worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_3445/897820363.py\", line 110, in ai_processing_worker\n",
      "ValueError: operands could not be broadcast together with shapes (1074,4) (2,) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping...\n",
      "[INFO] System Stopped\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b698b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92293003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac879ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64461c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c82af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97500e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3def7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6e2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630dc420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d294b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eea5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c612c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fedbd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e2535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2c72b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
